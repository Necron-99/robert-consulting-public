name: Legacy Direct Deployment (Deprecated)

# ‚ö†Ô∏è DEPRECATED: This workflow is replaced by staging-to-production-deployment.yml
# This workflow is kept for emergency deployments only

on:
  workflow_dispatch:
    inputs:
      emergency_deployment:
        description: 'Emergency deployment (bypasses staging and tests)'
        required: true
        default: false
        type: boolean
      skip_security_scan:
        description: 'Skip security scanning (not recommended)'
        required: false
        default: false
        type: boolean

jobs:
  emergency-deploy:
    name: üö® Emergency Direct Deployment
    runs-on: ubuntu-latest
    if: github.event.inputs.emergency_deployment == 'true'
    permissions:
      contents: read
      actions: read
      pull-requests: read
    
    steps:
    - name: ‚ö†Ô∏è Emergency Deployment Warning
      run: |
        echo "## üö® EMERGENCY DEPLOYMENT WARNING" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**‚ö†Ô∏è This is an emergency deployment that bypasses:**" >> $GITHUB_STEP_SUMMARY
        echo "- Staging environment testing" >> $GITHUB_STEP_SUMMARY
        echo "- Comprehensive test battery" >> $GITHUB_STEP_SUMMARY
        echo "- Manual approval process" >> $GITHUB_STEP_SUMMARY
        echo "- Security validation" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**üöÄ Deploying directly to production...**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**üìã Recommended next steps after deployment:**" >> $GITHUB_STEP_SUMMARY
        echo "1. Monitor production closely" >> $GITHUB_STEP_SUMMARY
        echo "2. Run post-deployment validation" >> $GITHUB_STEP_SUMMARY
        echo "3. Test critical functionality" >> $GITHUB_STEP_SUMMARY
        echo "4. Review logs for any issues" >> $GITHUB_STEP_SUMMARY
        
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
        
    - name: Run GitHub Copilot Security Scan
      run: |
        echo "üîç Running GitHub Copilot security scan..."
        
        # Initialize security variables
        SECURITY_STATUS="secure"
        DEPENDENCIES_STATUS="up-to-date"
        VULNERABILITIES_COUNT="0"
        HIGH_VULNERABILITIES="0"
        MEDIUM_VULNERABILITIES="0"
        LOW_VULNERABILITIES="0"
        CRITICAL_VULNERABILITIES="0"
        SECURITY_LAST_SCAN=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        
        # Check for CodeQL results
        if [ -f "codeql-results.sarif" ]; then
          echo "üìä Analyzing CodeQL results..."
          
          # Parse CodeQL SARIF results for security findings
          CRITICAL_VULNERABILITIES=$(jq -r '.runs[0].results[] | select(.ruleId | contains("security") or contains("vulnerability")) | select(.level == "error") | .ruleId' codeql-results.sarif 2>/dev/null | wc -l || echo "0")
          HIGH_VULNERABILITIES=$(jq -r '.runs[0].results[] | select(.ruleId | contains("security") or contains("vulnerability")) | select(.level == "warning") | .ruleId' codeql-results.sarif 2>/dev/null | wc -l || echo "0")
          MEDIUM_VULNERABILITIES=$(jq -r '.runs[0].results[] | select(.ruleId | contains("security") or contains("vulnerability")) | select(.level == "note") | .ruleId' codeql-results.sarif 2>/dev/null | wc -l || echo "0")
          
          VULNERABILITIES_COUNT=$((CRITICAL_VULNERABILITIES + HIGH_VULNERABILITIES + MEDIUM_VULNERABILITIES))
          
          # Determine security status based on CodeQL findings
          if [ "$CRITICAL_VULNERABILITIES" -gt 0 ]; then
            SECURITY_STATUS="critical-vulnerabilities"
            DEPENDENCIES_STATUS="critical-updates-needed"
          elif [ "$HIGH_VULNERABILITIES" -gt 0 ]; then
            SECURITY_STATUS="high-vulnerabilities"
            DEPENDENCIES_STATUS="high-priority-updates"
          elif [ "$MEDIUM_VULNERABILITIES" -gt 0 ]; then
            SECURITY_STATUS="medium-vulnerabilities"
            DEPENDENCIES_STATUS="recommended-updates"
          else
            SECURITY_STATUS="secure"
            DEPENDENCIES_STATUS="up-to-date"
          fi
        else
          echo "üìä No CodeQL results found, running basic security checks..."
        fi
        
        # Scan for common security issues in static files
        echo "üîç Scanning static files for security issues..."
        
        # Check for hardcoded secrets (basic scan)
        SECRETS_FOUND=0
        if grep -r -i "password\|secret\|key\|token" website/ --exclude-dir=node_modules --exclude="*.json" 2>/dev/null | grep -v "example\|placeholder\|TODO" | wc -l | grep -q "[1-9]"; then
          SECRETS_FOUND=1
          echo "‚ö†Ô∏è Potential secrets found in static files"
        fi
        
        # Check for outdated CDN links
        CDN_ISSUES=0
        if grep -r "http://" website/ --exclude-dir=node_modules 2>/dev/null | wc -l | grep -q "[1-9]"; then
          CDN_ISSUES=1
          echo "‚ö†Ô∏è HTTP links found (should use HTTPS)"
        fi
        
        # Update security status based on findings
        if [ "$SECRETS_FOUND" -eq 1 ] || [ "$CDN_ISSUES" -eq 1 ]; then
          if [ "$SECURITY_STATUS" = "secure" ]; then
            SECURITY_STATUS="security-issues-detected"
            DEPENDENCIES_STATUS="code-review-needed"
          fi
        fi
        
        echo "‚úÖ GitHub Copilot security scan completed:"
        echo "  Status: $SECURITY_STATUS"
        echo "  Total Vulnerabilities: $VULNERABILITIES_COUNT"
        echo "  Critical: $CRITICAL_VULNERABILITIES"
        echo "  High: $HIGH_VULNERABILITIES"
        echo "  Medium: $MEDIUM_VULNERABILITIES"
        echo "  Low: $LOW_VULNERABILITIES"
        
    - name: Generate Dynamic Version Information
      run: |
        echo "üìù Generating dynamic version information..."
        
        # Get current date in ISO format for build timestamp
        BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        
        # Generate version with major.minor.patch format
        # Use run number as patch version for production deployments
        VERSION="1.0.${{ github.run_number }}"
        
        # Determine release status based on branch
        if [ "${{ github.ref_name }}" = "main" ]; then
          RELEASE_STATUS="stable"
        else
          RELEASE_STATUS="development"
        fi
        
        # Version information is now generated dynamically by version-manager.js
        # No need to create static version.json files
        
        echo "‚úÖ Version information generated:"
        echo "  Version: $VERSION"
        echo "  Build Date: $BUILD_DATE"
        echo "  Release Status: $RELEASE_STATUS"
        echo "  Commit: ${{ github.sha }}"
        echo "  Security Status: $SECURITY_STATUS"
        
    - name: Make deployment script executable
      run: chmod +x website/deploy-website.sh
      
    - name: Deploy Website (Direct)
      run: |
        echo "üöÄ Deploying website files to S3..."
        
        # Set CloudFront distribution ID
        export CLOUDFRONT_DISTRIBUTION_ID=E36DBYPHUUKB3V
        BUCKET_NAME="robert-consulting-website"
        
        # Navigate to website directory and sync only website files
        cd website
        
        # Sync website files to S3 (excluding non-production files)
        echo "üö´ Excluding non-production files from deployment..."
        
        # Create a temporary directory with only production files
        mkdir -p temp-deploy
        
        # Copy only production files (exclude test files, scripts, etc.)
        rsync -av --exclude='easter-egg-test.html' \
                  --exclude='test-*.md' \
                  --exclude='test-*.html' \
                  --exclude='auth.js' \
                  --exclude='configure-api.*' \
                  --exclude='deploy-*.sh' \
                  --exclude='secure-api-deployment.sh' \
                  --exclude='update-version.*' \
                  --exclude='version-*.js' \
                  --exclude='version-fallback.json' \
                  --exclude='package.json' \
                  --exclude='api/' \
                  --exclude='security-config.js' \
                  --exclude='best-practices-script.js' \
                  --exclude='best-practices-styles.css' \
                  --exclude='best-practices.html' \
                  --exclude='dynamic-version.js' \
                  --exclude='dashboard-styles.css' \
                  --exclude='learning-styles.css' \
                  --exclude='monitoring-script.js' \
                  --exclude='monitoring-styles.css' \
                  --exclude='status-script.js' \
                  --exclude='status-styles.css' \
                  --exclude='script.js' \
                  --exclude='styles.css' \
                  --exclude='dashboard.json' \
                  --exclude='js/api-config.js' \
                  --exclude='*.tf' \
                  --exclude='*.tfvars' \
                  --exclude='*.tfstate' \
                  --exclude='*.tfstate.backup' \
                  --exclude='terraform/' \
                  . temp-deploy/
        
        cd temp-deploy
        
        # Deploy only the cleaned files
        aws s3 sync . s3://$BUCKET_NAME --delete
        
        # Clean up temporary directory
        cd ..
        rm -rf temp-deploy
        
        # Set proper content types for main files
        aws s3 cp s3://$BUCKET_NAME/index.html s3://$BUCKET_NAME/index.html --content-type "text/html" --metadata-directive REPLACE
        aws s3 cp s3://$BUCKET_NAME/dashboard.html s3://$BUCKET_NAME/dashboard.html --content-type "text/html" --metadata-directive REPLACE
        aws s3 cp s3://$BUCKET_NAME/learning.html s3://$BUCKET_NAME/learning.html --content-type "text/html" --metadata-directive REPLACE
        aws s3 cp s3://$BUCKET_NAME/monitoring.html s3://$BUCKET_NAME/monitoring.html --content-type "text/html" --metadata-directive REPLACE
        aws s3 cp s3://$BUCKET_NAME/css/main.css s3://$BUCKET_NAME/css/main.css --content-type "text/css" --metadata-directive REPLACE
        
        echo "‚úÖ Website files deployed to S3"
        
    - name: Invalidate CloudFront Cache (Always for Production)
      run: |
        echo "üîÑ Invalidating CloudFront cache for production deployment..."
        echo "üìã Distribution ID: E36DBYPHUUKB3V"
        echo "üìã Paths: /* (all content)"
        
        # Always create CloudFront invalidation for production deployments
        set -e  # Exit on any error
        
        INVALIDATION_ID=$(aws cloudfront create-invalidation \
          --distribution-id E36DBYPHUUKB3V \
          --paths "/*" \
          --query 'Invalidation.Id' \
          --output text)
        
        if [ -z "$INVALIDATION_ID" ]; then
          echo "‚ùå Failed to create CloudFront invalidation"
          exit 1
        fi
        
        echo "‚úÖ CloudFront invalidation created successfully: $INVALIDATION_ID"
        echo "üåê Cache invalidation will propagate globally within 15-20 minutes"
        
        # Store invalidation ID for potential use in subsequent steps
        echo "INVALIDATION_ID=$INVALIDATION_ID" >> $GITHUB_ENV
        
    - name: Wait for Invalidation (Optional)
      if: ${{ github.event.inputs.skip_security_scan == 'false' }}
      run: |
        echo "‚è≥ Waiting for CloudFront invalidation to complete..."
        echo "üìã Invalidation ID: $INVALIDATION_ID"
        
        while true; do
          STATUS=$(aws cloudfront get-invalidation \
            --distribution-id E36DBYPHUUKB3V \
            --id $INVALIDATION_ID \
            --query 'Invalidation.Status' \
            --output text)
          
          case $STATUS in
            "Completed")
              echo "‚úÖ Cache invalidation completed!"
              break
              ;;
            "InProgress")
              echo "‚è≥ Invalidation in progress... (Status: $STATUS)"
              sleep 30
              ;;
            *)
              echo "‚ö†Ô∏è Invalidation status: $STATUS"
              sleep 30
              ;;
          esac
        done
        
    - name: Deployment Summary
      run: |
        echo "üéâ Production Deployment Complete!"
        echo "=================================="
        echo "üì¶ S3 Bucket: robert-consulting-website"
        echo "üåê CloudFront Distribution: E36DBYPHUUKB3V"
        echo "üîÑ Cache Invalidation: $INVALIDATION_ID"
        echo "‚è∞ Deployment Time: $(date -u)"
        echo ""
        echo "üåç Your website is now live with fresh content!"
        echo "üìù Cache invalidation will complete within 15-20 minutes globally"
        
        
    - name: Deploy to Testing Site
      run: |
        echo "üß™ Deploying to testing site..."
        
        # Use the pre-configured testing bucket
        TESTING_BUCKET="robert-consulting-testing-site"
        echo "üîß Using pre-configured testing bucket: $TESTING_BUCKET"
        
        # Verify the bucket exists and is properly configured
        echo "üîç Verifying bucket configuration..."
        if aws s3api head-bucket --bucket $TESTING_BUCKET 2>/dev/null; then
          echo "‚úÖ Testing bucket exists and is accessible"
        else
          echo "‚ùå Testing bucket does not exist or is not accessible"
          echo "üîß Please run the manual setup to create the testing infrastructure first"
          exit 1
        fi
        
        # Sync website files to S3 (staging deployment) - exclude non-production files
        echo "üìÅ Syncing website files to S3 staging..."
        echo "üö´ Excluding non-production files from deployment..."
        
        # Create a temporary directory with only production files
        mkdir -p temp-deploy
        cd website
        
        # Copy only production files (exclude test files, scripts, etc.)
        rsync -av --exclude='easter-egg-test.html' \
                  --exclude='test-*.md' \
                  --exclude='test-*.html' \
                  --exclude='auth.js' \
                  --exclude='configure-api.*' \
                  --exclude='deploy-*.sh' \
                  --exclude='secure-api-deployment.sh' \
                  --exclude='update-version.*' \
                  --exclude='version-*.js' \
                  --exclude='version-fallback.json' \
                  --exclude='package.json' \
                  --exclude='api/' \
                  --exclude='security-config.js' \
                  --exclude='best-practices-script.js' \
                  --exclude='best-practices-styles.css' \
                  --exclude='best-practices.html' \
                  --exclude='dynamic-version.js' \
                  --exclude='dashboard-styles.css' \
                  --exclude='learning-styles.css' \
                  --exclude='monitoring-script.js' \
                  --exclude='monitoring-styles.css' \
                  --exclude='status-script.js' \
                  --exclude='status-styles.css' \
                  --exclude='script.js' \
                  --exclude='styles.css' \
                  --exclude='dashboard.json' \
                  --exclude='js/api-config.js' \
                  --exclude='*.tf' \
                  --exclude='*.tfvars' \
                  --exclude='*.tfstate' \
                  --exclude='*.tfstate.backup' \
                  --exclude='terraform/' \
                  . ../temp-deploy/
        
        cd ../temp-deploy
        
        # Deploy only the cleaned files
        aws s3 sync . s3://$TESTING_BUCKET --delete
        
        # Clean up temporary directory
        cd ..
        rm -rf temp-deploy
        
        echo "‚úÖ Testing site deployed successfully!"
        echo "  S3 Bucket: $TESTING_BUCKET"
        echo "  Website URL: http://$TESTING_BUCKET.s3-website-us-east-1.amazonaws.com"
